{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dc05287",
   "metadata": {},
   "source": [
    "# Text Summarization Demonstration\n",
    "\n",
    "This notebook demonstrates how to use the summarization API in the mood-map project. It shows both direct model usage and API interaction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae8e0ea",
   "metadata": {},
   "source": [
    "## 1. Direct Model Usage\n",
    "\n",
    "First, let's demonstrate how to use the text summarization model directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fece1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU availability\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device} for summarization model\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ede44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained summarization model\n",
    "model_name = \"facebook/bart-large-cnn\"  # Good balance of quality and speed\n",
    "print(f\"Loading model: {model_name}...\")\n",
    "\n",
    "start_time = time.time()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)\n",
    "print(f\"Model loaded in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "# Create a summarization pipeline\n",
    "summarizer = pipeline(\n",
    "    \"summarization\", \n",
    "    model=model, \n",
    "    tokenizer=tokenizer,\n",
    "    device=0 if device == \"cuda\" else -1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629daf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text to summarize\n",
    "article = \"\"\"\n",
    "Artificial intelligence (AI) is the intelligence of machines or software, as opposed to the intelligence of humans or animals. \n",
    "It is a field of study in computer science that develops and studies intelligent machines. Such machines may be called AIs.\n",
    "AI technology is widely used throughout industry, government and science. Some high-profile applications include advanced web search engines (e.g., Google Search), \n",
    "recommendation systems (used by YouTube, Amazon, and Netflix), understanding human speech (such as Siri and Alexa), self-driving cars (e.g., Waymo), \n",
    "generative and creative tools (ChatGPT and AI art), and superhuman play and analysis in strategy games (such as chess and Go).\n",
    "\n",
    "Artificial intelligence was founded as an academic discipline in 1956. The field went through multiple cycles of optimism followed by \n",
    "disappointment and loss of funding, but after 2012, advances in machine learning led to a resurgence, massive growth, \n",
    "and substantial industrial investment. Deep learning's growing capabilities and successes since the early 2010s laid the groundwork \n",
    "for advanced, widely available AI chatbots like Replika, ChatGPT, Google Bard, Claude, and Anthropic, \n",
    "along with image generators like DALL-E, Midjourney, and Stable Diffusion. This wave of generative AI, able to create novel text, images, \n",
    "audio, video, and code, has fueled a surge in public interest and conversation starting in 2022.\n",
    "\n",
    "Machine learning, which investigates algorithms that can learn from data, has been central to AI since its founding. Many modern AI \n",
    "systems are based on machine learning, Large Language Models, and other statistical approaches that analyze large amounts of data.\n",
    "These methods have shown successful recent application across many tasks, but they remain brittle in ways that humans are not: \n",
    "they can fail in unexpected ways, be biased, hallucinate non-factual statements, and generate toxic content.\n",
    "\n",
    "The long-term goal of artificial intelligence research is Artificial General Intelligence (AGI), a hypothetical form of AI that \n",
    "can learn to accomplish any intellectual task that human beings or other animals can. Risks of advanced AI have been debated \n",
    "since its founding and may pose an existential risk to humanity.\n",
    "\"\"\"\n",
    "print(f\"Original text length: {len(article.split())} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfa0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate summary\n",
    "start_time = time.time()\n",
    "summary = summarizer(article, max_length=150, min_length=40, do_sample=False)\n",
    "print(f\"Summarization completed in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "print(\"\\nSummary:\")\n",
    "print(summary[0]['summary_text'])\n",
    "print(f\"\\nSummary length: {len(summary[0]['summary_text'].split())} words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4fae05",
   "metadata": {},
   "source": [
    "## 2. Using the Backend API\n",
    "\n",
    "Now let's demonstrate how to use the summarization API endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44034e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Make sure your Flask backend is running\n",
    "API_URL = \"http://localhost:5000/summarize\"\n",
    "\n",
    "# Sample text (shorter than the previous one for variety)\n",
    "sample_text = \"\"\"\n",
    "Machine learning is a branch of artificial intelligence (AI) and computer science which focuses on the use of data and algorithms to \n",
    "imitate the way that humans learn, gradually improving its accuracy. IBM has a rich history with machine learning. One of its own, \n",
    "Arthur Samuel, is credited for coining the term, \"machine learning\" with his research (PDF, 481 KB) (link resides outside IBM) \n",
    "around the game of checkers. Robert Nealey, the self-proclaimed checkers master, played the game on an IBM 7094 computer in 1962, \n",
    "and he lost to the computer. Compared to what can be done today, this feat seems trivial, but it's considered a major milestone in \n",
    "the field of artificial intelligence.\n",
    "\n",
    "In the modern era, machine learning has been one of the most exciting technologies to emerge for decades and will continue to be \n",
    "a topic of discussion among industry and academic circles for a long time to come. Especially with the tremendous amount of data \n",
    "that is being produced today, from text to images and videos, across many sectors, intelligent systems that can learn from this data \n",
    "to improve their functioning and deliver better performance are bound to be incredibly valuable.\n",
    "\"\"\"\n",
    "\n",
    "# Function to make API request\n",
    "def get_summary_from_api(text, max_length=120, min_length=30):\n",
    "    try:\n",
    "        payload = {\n",
    "            \"text\": text,\n",
    "            \"max_length\": max_length,\n",
    "            \"min_length\": min_length\n",
    "        }\n",
    "        \n",
    "        response = requests.post(API_URL, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()\n",
    "        else:\n",
    "            return {\"error\": f\"API request failed with status code {response.status_code}: {response.text}\"}\n",
    "    except Exception as e:\n",
    "        return {\"error\": f\"Exception occurred: {str(e)}\"}\n",
    "\n",
    "# Note: You need to have your Flask backend running to execute this cell successfully\n",
    "print(\"To use this cell, make sure your backend Flask server is running first!\")\n",
    "print(\"Run the backend with: python backend/app.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9719dba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the API (uncomment to run)\n",
    "# result = get_summary_from_api(sample_text)\n",
    "# print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af838b3",
   "metadata": {},
   "source": [
    "## 3. Customizing the Summary Length\n",
    "\n",
    "Let's experiment with different summary lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79588e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model directly for different summary lengths\n",
    "def compare_summary_lengths(text):\n",
    "    # Short summary\n",
    "    short_summary = summarizer(text, max_length=60, min_length=30, do_sample=False)\n",
    "    \n",
    "    # Medium summary\n",
    "    medium_summary = summarizer(text, max_length=120, min_length=60, do_sample=False)\n",
    "    \n",
    "    # Long summary\n",
    "    long_summary = summarizer(text, max_length=180, min_length=90, do_sample=False)\n",
    "    \n",
    "    print(f\"Original text: {len(text.split())} words\")\n",
    "    \n",
    "    print(\"\\nShort summary:\")\n",
    "    print(short_summary[0]['summary_text'])\n",
    "    print(f\"Length: {len(short_summary[0]['summary_text'].split())} words\")\n",
    "    \n",
    "    print(\"\\nMedium summary:\")\n",
    "    print(medium_summary[0]['summary_text'])\n",
    "    print(f\"Length: {len(medium_summary[0]['summary_text'].split())} words\")\n",
    "    \n",
    "    print(\"\\nLong summary:\")\n",
    "    print(long_summary[0]['summary_text'])\n",
    "    print(f\"Length: {len(long_summary[0]['summary_text'].split())} words\")\n",
    "\n",
    "# Run on the article\n",
    "compare_summary_lengths(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c15369",
   "metadata": {},
   "source": [
    "## 4. Combining Sentiment Analysis and Summarization\n",
    "\n",
    "Now let's demonstrate how to use both sentiment analysis and summarization together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10416f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get sentiment analysis from the API\n",
    "def get_sentiment(text):\n",
    "    try:\n",
    "        sentiment_url = \"http://localhost:5000/analyze\"\n",
    "        payload = {\"text\": text}\n",
    "        response = requests.post(sentiment_url, json=payload)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"prediction\"]\n",
    "        else:\n",
    "            return f\"API request failed with status code {response.status_code}: {response.text}\"\n",
    "    except Exception as e:\n",
    "        return f\"Exception occurred: {str(e)}\"\n",
    "\n",
    "# Note: You need to have your Flask backend running to execute this cell successfully\n",
    "print(\"To use this cell, make sure your backend Flask server is running first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd68cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text with strong sentiment\n",
    "text_with_sentiment = \"\"\"\n",
    "The new restaurant that opened downtown last week is absolutely fantastic! I had the most amazing dining experience there. \n",
    "The ambiance was elegant yet comfortable, with soft lighting and tasteful decor that created a welcoming atmosphere. \n",
    "The service was impeccable - our server was attentive, knowledgeable about the menu, and made excellent recommendations. \n",
    "The food was the real star though. Every dish was beautifully presented and burst with flavor. The chef clearly uses only \n",
    "the freshest ingredients and has mastered the art of balancing flavors and textures. I started with the truffle risotto, \n",
    "which was creamy and rich with just the right amount of truffle. For the main course, I had the pan-seared sea bass with \n",
    "a lemon butter sauce that was light yet decadent. The dessert - a chocolate souffl√© with homemade vanilla ice cream - \n",
    "was pure perfection. I can't remember the last time I had such an outstanding meal from start to finish. The prices were \n",
    "reasonable considering the quality of food and overall experience. I've already made reservations to go back next week and \n",
    "can't wait to try more dishes. This place is destined to become the top dining destination in the city!\n",
    "\"\"\"\n",
    "\n",
    "# Generate summary\n",
    "summary_text = summarizer(text_with_sentiment, max_length=100, min_length=30, do_sample=False)[0]['summary_text']\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summary_text)\n",
    "print(f\"\\nSummary length: {len(summary_text.split())} words\")\n",
    "\n",
    "# Get sentiment for both original and summary (uncomment when API is available)\n",
    "# original_sentiment = get_sentiment(text_with_sentiment)\n",
    "# summary_sentiment = get_sentiment(summary_text)\n",
    "\n",
    "# print(f\"\\nOriginal text sentiment: {original_sentiment}\")\n",
    "# print(f\"Summary sentiment: {summary_sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf2e2aa",
   "metadata": {},
   "source": [
    "## 5. Batch Processing Multiple Texts\n",
    "\n",
    "Finally, let's see how to process multiple texts efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55f3000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample texts to summarize\n",
    "sample_texts = [\n",
    "    \"\"\"Climate change is the long-term alteration of temperature and typical weather patterns in a place. Climate change could refer to a particular location or the planet as a whole. Climate change may cause weather patterns to be less predictable. These unexpected weather patterns can make it difficult to maintain and grow crops in regions that rely on farming because expected temperature and rainfall levels can no longer be relied on. Climate change has also been connected with other damaging weather events such as more frequent and more intense hurricanes, floods, downpours, and winter storms.\"\"\",\n",
    "    \n",
    "    \"\"\"The COVID-19 pandemic, also known as the coronavirus pandemic, is an ongoing global pandemic of coronavirus disease 2019 (COVID-19) caused by severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The novel virus was first identified from an outbreak in Wuhan, China, in December 2019. Attempts to contain it there failed, allowing the virus to spread worldwide. The World Health Organization (WHO) declared a Public Health Emergency of International Concern on 30 January 2020 and a pandemic on 11 March 2020. As of 27 April 2025, the pandemic had caused more than 774 million confirmed cases and 6.98 million confirmed deaths, making it one of the deadliest in history.\"\"\",\n",
    "    \n",
    "    \"\"\"Renewable energy is useful energy that is collected from renewable resources, which are naturally replenished on a human timescale, including carbon-neutral sources like sunlight, wind, rain, tides, waves, and geothermal heat. This type of energy source stands in contrast to fossil fuels, which are being used far more quickly than they are being replenished. Renewable energy often provides energy in four important areas: electricity generation, air and water heating/cooling, transportation, and rural (off-grid) energy services.\"\"\"\n",
    "]\n",
    "\n",
    "# Process each text and time it\n",
    "total_start_time = time.time()\n",
    "\n",
    "for i, text in enumerate(sample_texts):\n",
    "    print(f\"\\nText {i+1} - Original length: {len(text.split())} words\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    summary = summarizer(text, max_length=60, min_length=20, do_sample=False)\n",
    "    process_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Summary (generated in {process_time:.2f} seconds):\")\n",
    "    print(summary[0]['summary_text'])\n",
    "    print(f\"Summary length: {len(summary[0]['summary_text'].split())} words\")\n",
    "\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"\\nTotal processing time for {len(sample_texts)} texts: {total_time:.2f} seconds\")\n",
    "print(f\"Average time per text: {total_time/len(sample_texts):.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
